import "../common/models.tsp";

namespace OpenAI;
using TypeSpec.OpenAPI;

model CreateEmbeddingRequest {
  /** ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them. */
  @extension("x-oaiTypeLabel", "string")
  `model`: string | "text-embedding-ada-002";

  /**
   * Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
   * single request, pass an array of strings or array of token arrays. Each input must not exceed
   * the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an empty string.
   * [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
   * for counting tokens.
   */
  input: string | string[] | TokenArray | TokenArrayArray;

  user?: User;
}
model CreateEmbeddingResponse {
  /** The object type, which is always "embedding". */
  object: "embedding";

  /** The name of the model used to generate the embedding. */
  `model`: string;

  /** The list of embeddings generated by the model. */
  data: Embedding[];

  /** The usage information for the request. */
  usage: {
    /** The number of tokens used by the prompt. */
    prompt_tokens: safeint;

    /** The total number of tokens used by the request. */
    total_tokens: safeint;
  };
}

/** Represents an embedding vector returned by embedding endpoint. */
model Embedding {
  /** The index of the embedding in the list of embeddings. */
  index: safeint;

  /** The object type, which is always "embedding". */
  object: "embedding";

  /**
   * The embedding vector, which is a list of floats. The length of vector depends on the model as\
   * listed in the [embedding guide](/docs/guides/embeddings).
   */
  embedding: float64[];
}
